# Brazilian E-Commerce Public Dataset by Olist
https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/data

## **åˆ†æç›®æ¨™**
 
- ç›®æ¨™å®¢ç¾¤ï¼ˆWhoï¼‰ï¼šå·²ç¶“å®Œæˆé¦–è³¼çš„å®¢æˆ¶ï¼Œé æ¸¬ã€Œèª°æœƒå†æ¬¡è³¼è²·ã€ã€‚

- ç›®æ¨™è¡Œç‚ºï¼ˆWhatï¼‰ï¼šé æ¸¬å“ªäº›å®¢æˆ¶æœƒå›è³¼ã€‚

- å•†æ¥­åƒ¹å€¼ï¼ˆWhyï¼‰ï¼šé‡å°é«˜æ©Ÿç‡å›è³¼å®¢æˆ¶é€²è¡Œå»£å‘Šå†è¡ŒéŠ·ï¼Œæå‡è½‰æ›ç‡ä¸¦é™ä½å»£å‘Šæµªè²»ï¼Œæé«˜ROASã€‚

## **åˆ†æå•é¡Œ**

- å“ªäº›å®¢æˆ¶æœ‰æœ€é«˜æ©Ÿç‡å†æ¬¡è³¼è²·ï¼Ÿ

- å“ªäº›ä»˜æ¬¾æ–¹å¼ã€åœ°å€æˆ–å•†å“é¡åˆ¥çš„å®¢æˆ¶å¿ èª åº¦è¼ƒé«˜ï¼Ÿ

- å¦‚ä½•é€éç²¾æº–æŠ•æ”¾å»£å‘Šï¼Œæé«˜å›è³¼è½‰æ›ç‡ä¸¦é™ä½ CPAï¼Ÿ

## **ç›®éŒ„**

[1. è³‡æ–™æ•´ç†](#1-è³‡æ–™æ•´ç†)

[2. ç‰¹å¾µå·¥ç¨‹](#2-ç‰¹å¾µå·¥ç¨‹)

[3. æ¼æ–—åˆ†æ](#3-æ¼æ–—åˆ†æ)

[4. å»ºç«‹é æ¸¬æ¨¡å‹ (LightGBM)](#4-å»ºç«‹é æ¸¬æ¨¡å‹-LightGBM)

[5. å®¢æˆ¶åˆ†ç¾¤åˆ†æ](#5-å®¢æˆ¶åˆ†ç¾¤åˆ†æ-Audience-Segmentation)

[6. çµè«–èˆ‡å»ºè­°](#6-çµè«–èˆ‡å»ºè­°)

---

### **1. è³‡æ–™æ•´ç†**

| è¡¨æ ¼åç¨±             | ä¸»è¦å…§å®¹   | ç”¨é€”                |
| ---------------- | ------ | ----------------- |
| `orders`     | è¨‚å–®è³‡æ–™   | è¨ˆç®—é¦–æ¬¡è³¼è²·ã€å›è³¼è¡Œç‚ºæ¨™è¨˜ |
| `customers` | å®¢æˆ¶åŸºæœ¬è³‡æ–™   |  åˆ†æåœ°å€ã€å®¢æˆ¶é¡å‹ç­‰ç‰¹å¾µ   |
| `order_items`  | å•†å“æ˜ç´° | è¨ˆç®—æ¶ˆè²»é‡‘é¡ã€å•†å“é¡åˆ¥      |
| `order_payments` | ä»˜æ¬¾è³‡æ–™   | ä»˜æ¬¾æ–¹å¼åˆ†æ       |



```python
# !pip install pandas
```


```python
import pandas as pd

# è¼‰å…¥ Olist ä¸»è¦è³‡æ–™è¡¨
orders = pd.read_csv('olist_orders_dataset.csv')
customers = pd.read_csv('olist_customers_dataset.csv')
order_items = pd.read_csv('olist_order_items_dataset.csv')
payments = pd.read_csv('olist_order_payments_dataset.csv')
```

å»ºç«‹ç›®æ¨™è®Šæ•¸ - æ˜¯å¦å†æ¬¡è³¼è²·

- é€£æ¥ `customer_id` èˆ‡ `customer_unique_id`


```python
customer_lookup = customers[['customer_id', 'customer_unique_id']]
orders = orders.merge(customer_lookup, on='customer_id', how='left')
```


```python
# merge() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å°‡å…©å€‹ DataFrame é€²è¡Œåˆä½µ
# on æ˜¯ä¸€å€‹åƒæ•¸ï¼Œç”¨ä¾†æŒ‡å®šåˆä½µçš„æ¬„ä½(å°æ‡‰æ¬„ä½)(æ¬„ä½åç¨±ç›¸åŒ)
# how æ˜¯ä¸€å€‹åƒæ•¸ï¼Œç”¨ä¾†æŒ‡å®šåˆä½µçš„æ–¹å¼
# 'left' ä»£è¡¨å·¦é‚Šçš„ DataFrame ç‚ºä¸»ï¼Œå³é‚Šçš„ DataFrame ç‚ºè¼”
# é€™æ¨£çš„åˆä½µæ–¹å¼æœƒä¿ç•™å·¦é‚Š DataFrame çš„æ‰€æœ‰è³‡æ–™
# å³é‚Š DataFrame çš„è³‡æ–™æœƒæ ¹æ“šå·¦é‚Š DataFrame çš„è³‡æ–™é€²è¡Œåˆä½µ
```

- è¨ˆç®—æ¯ä½å®¢æˆ¶çš„è¨‚å–®æ¬¡æ•¸


```python
customer_order_counts = orders.groupby('customer_unique_id')['order_id'].count().reset_index()
customer_order_counts.columns = ['customer_unique_id', 'order_count']
```


```python
# groupby() æ˜¯ä¸€å€‹åˆ†çµ„å‡½æ•¸ï¼Œç”¨ä¾†å°‡è³‡æ–™ä¾ç…§æŸå€‹æ¬„ä½é€²è¡Œåˆ†çµ„
# count() æ˜¯ä¸€å€‹èšåˆå‡½æ•¸ï¼Œç”¨ä¾†è¨ˆç®—æ¯å€‹å®¢æˆ¶çš„è¨‚å–®æ•¸é‡
# reset_index() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å°‡åˆ†çµ„å¾Œçš„çµæœè½‰æ›æˆ DataFrame æ ¼å¼
# columns æ˜¯ä¸€å€‹å±¬æ€§ï¼Œç”¨ä¾†è¨­å®š DataFrame çš„æ¬„ä½åç¨±
```

- è¨­å®šç›®æ¨™è®Šæ•¸ `is_repurchase`ï¼šè¨‚å–®æ•¸ â‰¥ 2 å°±ç®—æœ‰å›è³¼ã€‚


```python
customer_order_counts['is_repurchase'] = (customer_order_counts['order_count'] >= 2).astype(int)
```


```python
# astype() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å°‡è³‡æ–™è½‰æ›æˆæŒ‡å®šçš„è³‡æ–™å‹åˆ¥
```


```python
customer_order_counts.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_unique_id</th>
      <th>order_count</th>
      <th>is_repurchase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0000f46a3911fa3c0805444483337064</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0000f6ccb0745a6a4b88665a16c9f078</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0004aac84e0df4da2b147fca70cf8255</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

[ğŸ”¼è¿”å›ç›®éŒ„](#ç›®éŒ„)


### **2. ç‰¹å¾µå·¥ç¨‹**

ğŸ“Œ **RFM** 

Recency (å‡è¨­èˆ‡æ•´å€‹è³‡æ–™é›†æœ€å¾Œä¸€æ¬¡è³¼è²·çš„å¤©æ•¸å·®è·)


```python
orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])
last_order_date = orders['order_purchase_timestamp'].max() # è³‡æ–™ä¸­æœ€å¾Œä¸€ç­†è¨‚å–®çš„è³¼è²·æ—¥æœŸ

recency_df = orders.groupby('customer_unique_id')['order_purchase_timestamp'].max().reset_index()
recency_df['recency_days'] = (last_order_date - recency_df['order_purchase_timestamp']).dt.days
recency_df.drop(columns='order_purchase_timestamp', inplace=True)

```


```python
# to_datetime() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å°‡å­—ä¸²è½‰æ›æˆæ—¥æœŸæ™‚é–“æ ¼å¼
# max() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†è¨ˆç®—æ¯å€‹å®¢æˆ¶çš„æœ€å¾Œè¨‚å–®æ—¥æœŸ
# dt æ˜¯ä¸€å€‹å±¬æ€§ï¼Œç”¨ä¾†å­˜å–æ—¥æœŸæ™‚é–“æ ¼å¼çš„å±¬æ€§
# days æ˜¯ä¸€å€‹å±¬æ€§ï¼Œç”¨ä¾†è¨ˆç®—æ—¥æœŸæ™‚é–“æ ¼å¼çš„å¤©æ•¸å·®
# drop() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†åˆªé™¤æŒ‡å®šçš„æ¬„ä½
# inplace æ˜¯ä¸€å€‹åƒæ•¸ï¼Œç”¨ä¾†æŒ‡å®šæ˜¯å¦åœ¨åŸå§‹è³‡æ–™ä¸Šé€²è¡Œä¿®æ”¹
```

Frequencyï¼ˆè³¼è²·é »ç‡ï¼‰


```python
# customer_order_counts['order_count']
```

Monetaryï¼ˆå¹³å‡æ¶ˆè²»é‡‘é¡ï¼‰


```python
order_items['price_total'] = order_items['price'] + order_items['freight_value'] # freight_value é‹è²»
order_values = order_items.groupby('order_id')['price_total'].sum().reset_index()
orders_monetary = orders[['order_id', 'customer_unique_id']].merge(order_values, on='order_id')

monetary_df = orders_monetary.groupby('customer_unique_id')['price_total'].mean().reset_index()
monetary_df.columns = ['customer_unique_id', 'monetary_avg']
```


```python
# sum() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†è¨ˆç®—æ¯å€‹è¨‚å–®çš„ç¸½é‡‘é¡
# mean() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†è¨ˆç®—æ¯å€‹å®¢æˆ¶çš„å¹³å‡è¨‚å–®é‡‘é¡
```

ğŸ“Œ **ä»˜æ¬¾æ–¹å¼**


```python
payments_mode = payments.groupby(['order_id', 'payment_type']).size().unstack(fill_value=0).reset_index() # One-Hot Encoding
orders_payments = orders[['order_id', 'customer_unique_id']].merge(payments_mode, on='order_id')
payment_summary = orders_payments.groupby('customer_unique_id').sum().reset_index()
```


```python
# size() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†è¨ˆç®—æ¯å€‹è¨‚å–®çš„ä»˜æ¬¾æ–¹å¼æ•¸é‡
# unstack() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å°‡è³‡æ–™è½‰æ›æˆå¯¬æ ¼å¼ 
# å¯¬æ ¼å¼æŒ‡è³‡æ–™è¡¨æ ¼ä¸­ï¼Œæ¯ä¸€åˆ—ä»£è¡¨ä¸€å€‹è§€å¯Ÿå–®ä½ï¼Œè€Œä¸åŒæ¬„ä½å‰‡ä»£è¡¨è©²å–®ä½åœ¨ä¸åŒæ™‚é–“é»æˆ–ä¸åŒè®Šæ•¸ä¸‹çš„è§€å¯Ÿå€¼ã€‚
# fill_value æ˜¯ä¸€å€‹åƒæ•¸ï¼Œç”¨ä¾†æŒ‡å®šå¡«å…¥çš„å€¼
```

ğŸ“Œ **å®¢æˆ¶æ‰€å±¬å·åˆ¥**


```python
customer_states = customers[['customer_unique_id', 'customer_state']]
```

åˆä½µæ‰€æœ‰ç‰¹å¾µèˆ‡ç›®æ¨™è®Šæ•¸


```python
# åˆä½µæ‰€æœ‰è³‡æ–™è¡¨
features = customer_order_counts.merge(recency_df, on='customer_unique_id', how='left')
features = features.merge(monetary_df, on='customer_unique_id', how='left')
features = features.merge(payment_summary, on='customer_unique_id', how='left')
features = features.merge(customer_states, on='customer_unique_id', how='left')

# å¡«è£œç¼ºå¤±å€¼
features.fillna(0, inplace=True)
```


```python
# fillna() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å¡«è£œç¼ºå¤±å€¼
# inplace æ˜¯ä¸€å€‹åƒæ•¸ï¼Œç”¨ä¾†æŒ‡å®šæ˜¯å¦åœ¨åŸå§‹è³‡æ–™ä¸Šé€²è¡Œä¿®æ”¹
```


```python
features.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_unique_id</th>
      <th>order_count</th>
      <th>is_repurchase</th>
      <th>recency_days</th>
      <th>monetary_avg</th>
      <th>order_id</th>
      <th>boleto</th>
      <th>credit_card</th>
      <th>debit_card</th>
      <th>not_defined</th>
      <th>voucher</th>
      <th>customer_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>
      <td>1</td>
      <td>0</td>
      <td>160</td>
      <td>141.90</td>
      <td>e22acc9c116caa3f2b7121bbb380d08e</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>
      <td>1</td>
      <td>0</td>
      <td>163</td>
      <td>27.19</td>
      <td>3594e05a005ac4d06a72673270ef9ec9</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0000f46a3911fa3c0805444483337064</td>
      <td>1</td>
      <td>0</td>
      <td>585</td>
      <td>86.22</td>
      <td>b33ec3b699337181488304f362a6b734</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>SC</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0000f6ccb0745a6a4b88665a16c9f078</td>
      <td>1</td>
      <td>0</td>
      <td>369</td>
      <td>43.62</td>
      <td>41272756ecddd9a9ed0180413cc22fb6</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>PA</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0004aac84e0df4da2b147fca70cf8255</td>
      <td>1</td>
      <td>0</td>
      <td>336</td>
      <td>196.89</td>
      <td>d957021f1127559cd947b62533f484f7</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div>

[ğŸ”¼è¿”å›ç›®éŒ„](#ç›®éŒ„)

### **3. æ¼æ–—åˆ†æ**

å»ºç«‹æ¼æ–—å„éšæ®µäººæ•¸


```python
# è¨ˆç®—æ‰€æœ‰æ›¾è³¼è²·éçš„å®¢æˆ¶æ•¸
total_customers = features['customer_unique_id'].nunique()

# è¨ˆç®—æœ‰å›è³¼çš„å®¢æˆ¶æ•¸
repurchase_customers = features[features['is_repurchase'] == 1]['customer_unique_id'].nunique()

print(f"ç¸½è³¼è²·å®¢æˆ¶æ•¸: {total_customers}")
print(f"å›è³¼å®¢æˆ¶æ•¸: {repurchase_customers}")
```

    ç¸½è³¼è²·å®¢æˆ¶æ•¸: 96096
    å›è³¼å®¢æˆ¶æ•¸: 2997
    


```python
# nunique() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†è¨ˆç®—å”¯ä¸€å€¼çš„æ•¸é‡
```

è¨ˆç®—è½‰æ›ç‡


```python
conversion_rate = repurchase_customers / total_customers * 100
print(f"å›è³¼è½‰æ›ç‡ï¼š{conversion_rate:.2f}%")
```

    å›è³¼è½‰æ›ç‡ï¼š3.12%
    


```python
# .2fè¡¨ç¤ºä¿ç•™å…©ä½å°æ•¸
```

è¦–è¦ºåŒ–æ¼æ–—åœ–


```python
import matplotlib.pyplot as plt

# æ¼æ–—éšæ®µèˆ‡å°æ‡‰æ•¸å€¼
stages = ['First Purchase', 'Repurchase']
values = [total_customers, repurchase_customers]

# ç¹ªè£½æ°´å¹³é•·æ¢åœ–
plt.figure(figsize=(6, 4))
bars = plt.barh(stages, values, color=['skyblue', 'steelblue'])

plt.xlabel('Number of Customers')
plt.title('Repurchase Funnel Analysis')

# åè½‰ Y è»¸ï¼Œç¬¦åˆæ¼æ–—å¾ä¸Šåˆ°ä¸‹çš„è¦–è¦ºæ•ˆæœ
plt.gca().invert_yaxis()

# åœ¨é•·æ¢ä¸Šæ¨™è¨»æ•¸å€¼èˆ‡ç™¾åˆ†æ¯”
for bar, value in zip(bars, values):
    percent = value / total_customers * 100
    plt.text(value, bar.get_y() + bar.get_height() / 2, 
             f'{value} ({percent:.2f}%)', 
             va='center', ha='left', fontsize=10)

plt.tight_layout()
plt.show()

```


    
![png](practice_files/practice_45_0.png)
    



```python
import plotly.graph_objects as go

# æ¼æ–—éšæ®µèˆ‡æ•¸å€¼
stages = ['First Purchase', 'Repurchase']
values = [total_customers, repurchase_customers]

# ç¹ªè£½æ¼æ–—åœ–
fig = go.Figure(go.Funnel(
    y=stages,  # æ¼æ–—éšæ®µ
    x=values,  # å°æ‡‰æ•¸å€¼
    textinfo="value+percent initial",  # é¡¯ç¤ºäººæ•¸ + åˆå§‹ç™¾åˆ†æ¯”
    marker={"color": ["skyblue", "steelblue"]}  # è‡ªè¨‚é¡è‰²
))

fig.update_layout(
    title="Repurchase Funnel Analysis",
    width=600,
    height=400,
    font={"family": "Arial", "size": 14}
)

fig.show()


```



åˆ†æä¸åŒå®¢ç¾¤å›è³¼è½‰æ›ç‡

- ä¾æ“šå·åˆ¥ (customer_state) åˆ†æ


```python
# è¨ˆç®—å„å·å›è³¼è½‰æ›ç‡
state_summary = features.groupby('customer_state')['is_repurchase'].agg(['count', 'sum'])
state_summary['repurchase_rate'] = state_summary['sum'] / state_summary['count'] * 100
state_summary = state_summary.sort_values('repurchase_rate', ascending=False)

# é¡¯ç¤ºå‰å¹¾å€‹å·
print(state_summary[['repurchase_rate']].head())

```

                    repurchase_rate
    customer_state                 
    AC                     9.876543
    RO                     9.486166
    RJ                     6.979458
    MT                     6.835722
    GO                     6.633663
    


```python
# agg() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å°åˆ†çµ„å¾Œçš„è³‡æ–™é€²è¡Œå¤šé‡èšåˆ # è¨ˆç®—æ¯å€‹å·çš„å®¢æˆ¶æ•¸ã€è¨ˆç®—ã€Œæœ‰å›è³¼è¡Œç‚ºã€çš„å®¢æˆ¶æ•¸
# sort_values() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å°è³‡æ–™é€²è¡Œæ’åº
# ascending æ˜¯ä¸€å€‹åƒæ•¸ï¼Œç”¨ä¾†æŒ‡å®šæ’åºçš„æ–¹å¼
# True ä»£è¡¨å‡å†ªæ’åºï¼ŒFalse ä»£è¡¨é™å†ªæ’åº > ç”±å¤§åˆ°å°æ’åºï¼ˆéæ¸›ï¼‰
```


```python
# è¦–è¦ºåŒ–åœ–è¡¨

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.bar(state_summary.index, state_summary['repurchase_rate'], color='skyblue')
plt.xticks(rotation=45)
plt.ylabel('Repurchase Conversion Rate (%)')
plt.title('Repurchase Rate by State')
plt.tight_layout()
plt.show()
```


    
![png](practice_files/practice_51_0.png)
    


- ä¾æ“šä»˜æ¬¾æ–¹å¼åˆ†æ


```python
# æ‰¾å‡ºæ¯ä½å®¢æˆ¶ä¸»è¦çš„ä»˜æ¬¾æ–¹å¼

# ä»˜æ¬¾æ–¹å¼æ¬„ä½ï¼ˆæ ¹æ“šå‰é¢ features è£½ä½œçš„è³‡æ–™è¡¨ï¼‰
payment_columns = ['credit_card', 'boleto', 'voucher', 'debit_card']

# å°‹æ‰¾æ¯ä½å®¢æˆ¶æœ€å¸¸ç”¨çš„ä»˜æ¬¾æ–¹å¼
features['main_payment'] = features[payment_columns].idxmax(axis=1)
```


```python
# idmax() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å°‹æ‰¾æ¯ä¸€è¡Œåˆ—ä¸­æœ€å¤§å€¼çš„ç´¢å¼•
# axis=1 ä»£è¡¨æ²¿è‘—åˆ—çš„æ–¹å‘å°‹æ‰¾æœ€å¤§å€¼ 
# axis=0 ä»£è¡¨æ²¿è‘—è¡Œçš„æ–¹å‘å°‹æ‰¾æœ€å¤§å€¼
```


```python
# è¨ˆç®—å›è³¼è½‰æ›ç‡

payment_summary = features.groupby('main_payment')['is_repurchase'].agg(['count', 'sum'])
payment_summary['repurchase_rate'] = payment_summary['sum'] / payment_summary['count'] * 100
payment_summary = payment_summary.sort_values('repurchase_rate', ascending=False)

print(payment_summary[['repurchase_rate']])
```

                  repurchase_rate
    main_payment                 
    voucher              9.378238
    credit_card          6.669110
    boleto               5.276024
    debit_card           2.029770
    


```python
# è¦–è¦ºåŒ–åœ–è¡¨

plt.figure(figsize=(6, 4))
plt.bar(payment_summary.index, payment_summary['repurchase_rate'], color='steelblue')
plt.ylabel('Repurchase Conversion Rate (%)')
plt.title('Repurchase Rate by Payment Method')
plt.tight_layout()
plt.show()
```


    
![png](practice_files/practice_56_0.png)
    
[ğŸ”¼è¿”å›ç›®éŒ„](#ç›®éŒ„)

### **4. å»ºç«‹é æ¸¬æ¨¡å‹ (LightGBM)** 

è™•ç†åˆ†é¡è®Šæ•¸


```python
# !pip install lightgbm
# pip install --upgrade lightgbm
```


```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# è¨ˆç®—å„å·å›è³¼ç‡
state_summary = features.groupby('customer_state')['is_repurchase'].agg(['count', 'sum'])
state_summary['repurchase_rate'] = state_summary['sum'] / state_summary['count'] * 100

# Label Encoding
# å°‡æ–‡å­—é¡åˆ¥æ¬„ä½è½‰æ›ç‚ºæ•¸å€¼å‹æ…‹
le = LabelEncoder()
features['customer_state_encoded'] = le.fit_transform(features['customer_state'])

# åˆªé™¤åŸå§‹çš„æ–‡å­—é¡åˆ¥æ¬„ä½
features.drop(columns=['customer_state'], inplace=True)


# è§£æ±º main_payment çš„ object å‹æ…‹

# å°‡ main_payment ç¼ºå¤±å€¼è™•ç†æˆ 'unknown'ï¼Œé¿å… NaN å•é¡Œ
features['main_payment'] = features['main_payment'].fillna('unknown')

# One-Hot Encoding main_payment æ¬„ä½
features = pd.get_dummies(features, columns=['main_payment'], drop_first=True)

# è™•ç†ä»˜æ¬¾æ–¹å¼æ¬¡æ•¸çµ±è¨ˆæ¬„ä½ï¼ˆè®Šæˆ 0/1 æ˜¯å¦ä½¿ç”¨éï¼‰
payment_cols = ['credit_card', 'boleto', 'voucher', 'debit_card']

for col in payment_cols:
    if col in features.columns:
        features[col] = (features[col] > 0).astype(int)

```


```python
# apply() æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œç”¨ä¾†å°è³‡æ–™é€²è¡Œé€è¡Œæˆ–é€åˆ—çš„æ“ä½œ
# lambda æ˜¯ä¸€å€‹åŒ¿åå‡½æ•¸ï¼Œç”¨ä¾†å®šç¾©ç°¡å–®çš„å‡½æ•¸
# .dtype() æ˜¯ä¸€å€‹å±¬æ€§ï¼Œç”¨ä¾†æª¢æŸ¥è³‡æ–™çš„å‹æ…‹
# drop_first=True ä»£è¡¨åˆªé™¤ç¬¬ä¸€å€‹é¡åˆ¥ï¼Œé¿å…è™›æ“¬è®Šæ•¸é™·é˜±
# è™›æ“¬è®Šæ•¸é™·é˜±æ˜¯æŒ‡åœ¨é€²è¡Œè¿´æ­¸åˆ†ææ™‚ï¼Œç•¶æœ‰å¤šå€‹é¡åˆ¥è®Šæ•¸æ™‚ï¼Œæœƒå°è‡´å¤šé‡å…±ç·šæ€§å•é¡Œ
```

åˆªé™¤ç„¡æ„ç¾©çš„è­˜åˆ¥æ¬„ä½ 


```python
drop_cols = ['customer_unique_id', 'order_id', 'is_repurchase', 'order_count', 'recency_days'] 
X = features.drop(columns=drop_cols)
y = features['is_repurchase']

# å¡«è£œç¼ºå¤±å€¼ï¼ˆä»¥é˜²è¬ä¸€ï¼‰
X = X.fillna(0)
```


```python
# ç‚ºäº†é¿å…è³‡æ–™æ´©æ¼ï¼Œåˆªé™¤'is_repurchase', 'order_counts', 'recency_days'ã€‚å›è³¼æ¬¡æ•¸å¤šæœˆæœƒå›è³¼ã€æœ€è¿‘ä¸€æ¬¡è³¼è²·æ™‚é–“è¶Šé•·è¶Šä¸æœƒå›è³¼
# é€™æ˜¯å› ç‚ºæˆ‘å€‘è¦é æ¸¬çš„ç›®æ¨™è®Šæ•¸å°±æ˜¯'is_repurchase'ï¼Œå¦‚æœåœ¨ç‰¹å¾µä¸­ä¿ç•™å®ƒï¼Œæ¨¡å‹å°±æœƒçŸ¥é“ç­”æ¡ˆ
```

åˆ‡åˆ†è¨“ç·´é›† / æ¸¬è©¦é›†


```python
# ç”¨ customer_unique_id åšåˆ†çµ„åˆ‡åˆ†
# å¦‚æœéš¨æ©Ÿåˆ‡åˆ†è³‡æ–™é›†ï¼ŒåŒä¸€ä½æ¶ˆè²»è€…è¡Œç‚ºå¯èƒ½åŒæ™‚å‡ºç¾åœ¨è¨“ç·´é›†èˆ‡æ¸¬è©¦é›†
# æœƒé€ æˆæ¨¡å‹ã€Œå·çœ‹æœªä¾†ã€çš„è³‡è¨Šæ´©æ¼ï¼ˆData Leakageï¼‰ï¼Œå°è‡´æ¸¬è©¦çµæœéæ–¼æ¨‚è§€
# é€™æ¨£çš„åˆ‡åˆ†æ–¹å¼å¯ä»¥ç¢ºä¿æ¯ä½å®¢æˆ¶åªå‡ºç¾åœ¨è¨“ç·´é›†æˆ–æ¸¬è©¦é›†ä¸­ï¼Œé¿å…è³‡æ–™æ´©æ¼çš„å•é¡Œ

from sklearn.model_selection import GroupShuffleSplit

groups = features['customer_unique_id']
gss = GroupShuffleSplit(test_size=0.2, random_state=42)
train_idx, test_idx = next(gss.split(X, y, groups=groups))

X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
```


```python
# GroupShuffleSplit åˆ†çµ„éš¨æ©Ÿåˆ‡åˆ†å™¨ï¼Œå¯ä»¥æ ¹æ“šæŸå€‹ã€Œç¾¤çµ„æ¨™ç±¤ã€ä¾†åˆ‡åˆ†è³‡æ–™é›†
# test_size=0.2 â†’ æ¸¬è©¦é›†ä½” 20%ï¼Œè¨“ç·´é›†ä½” 80%
# random_state=42 â†’ å›ºå®šäº‚æ•¸ç¨®å­ï¼Œç¢ºä¿åˆ‡åˆ†çµæœå¯é‡ç¾
# gss.split() æ ¹æ“š groups ä¾†åˆ‡åˆ†è³‡æ–™ï¼Œä¸æœƒç›´æ¥ç”¢ç”Ÿåˆ‡åˆ†çµæœï¼Œè€Œæ˜¯å›å‚³ä¸€å€‹ generator ç‰©ä»¶ã€‚
# é€™å€‹ generator å¯ä»¥ç”¢ç”Ÿã€Œå¤šçµ„ä¸åŒçš„åˆ‡åˆ†ç´¢å¼•ã€ï¼Œæ¯æ¬¡å‘¼å«éƒ½èƒ½ç”¢ç”Ÿæ–°çš„åˆ‡åˆ†ï¼ˆé¡ä¼¼æ‰¹æ¬¡è³‡æ–™çš„æ¦‚å¿µï¼‰ã€‚
# next(gss.split(X, y, groups=groups)) è¡¨ç¤ºã€Œåªè¦ç¬¬ä¸€çµ„åˆ‡åˆ†çµæœå°±å¥½ã€ï¼Œä¸éœ€è¦ç”¢ç”Ÿå¤šçµ„è³‡æ–™åˆ‡åˆ†æ–¹æ¡ˆ
# æœƒå¾ generator ç‰©ä»¶ä¸­ï¼Œå–å‡ºç¬¬ä¸€å€‹ç”¢ç”Ÿçš„çµæœã€‚ï¼ˆå¸¸è¦‹æ–¼å–®æ¬¡å¯¦é©—ï¼‰
# .iloc æ ¹æ“šç´¢å¼•ä½ç½®é¸å–è³‡æ–™ã€‚ä½ç½®ç´¢å¼•ï¼ˆ0, 1, 2ï¼‰ã€‚.iloc[0] â†’ ç¬¬ä¸€ç­†è³‡æ–™
# .loc index æ¨™ç±¤å€¼ã€‚.loc[101] â†’ æ¨™ç±¤æ˜¯ 101 çš„è³‡æ–™

# å¯ä»¥å¤šæ¬¡åŸ·è¡Œæ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°ï¼ˆé¡ä¼¼äº¤å‰é©—è­‰ï¼‰
# for train_idx, test_idx in gss.split(X, y, groups=groups):
```

å»ºç«‹æ¨¡å‹


```python
from lightgbm import LGBMClassifier
from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, classification_report

model = LGBMClassifier(
    objective='binary',
    learning_rate=0.05,
    num_leaves=15,             # é™ä½è¤‡é›œåº¦é˜²æ­¢éæ“¬åˆ
    max_depth=5,               # æ§åˆ¶æ¨¹çš„æœ€å¤§æ·±åº¦
    n_estimators=1000,         # æé«˜ç–Šä»£æ¬¡æ•¸ï¼Œæ­é… early stopping ä½¿ç”¨
    reg_alpha=0.1,             # L1 æ­£å‰‡åŒ–ï¼Œé˜²æ­¢éæ“¬åˆ
    reg_lambda=0.1,            # L2 æ­£å‰‡åŒ–ï¼Œé˜²æ­¢éæ“¬åˆ
    class_weight='balanced',   # è‡ªå‹•è™•ç†è³‡æ–™ä¸å¹³è¡¡å•é¡Œ
    random_state=42
)
```

| åƒæ•¸                        | èªªæ˜                                                   |
| ------------------------- | ---------------------------------------------------- |
| `objective='binary'`      | æŒ‡å®šé€™æ˜¯ã€Œ**äºŒå…ƒåˆ†é¡å•é¡Œ**ã€ï¼Œé©ç”¨æ–¼ 0/1 é æ¸¬ï¼ˆå¦‚ï¼šå›è³¼ vs æœªå›è³¼ï¼‰ã€‚            |
| `learning_rate=0.05`      | å­¸ç¿’ç‡ï¼Œæ§åˆ¶æ¯æ¬¡æ¨¹çš„èª¿æ•´å¹…åº¦ï¼Œæ•¸å€¼è¶Šå°å­¸ç¿’è¶Šæ…¢ä½†æ³›åŒ–æ•ˆæœé€šå¸¸è¼ƒå¥½ã€‚                    |
| `num_leaves=15`           | æ¯æ£µæ¨¹çš„æœ€å¤§è‘‰ç¯€é»æ•¸ï¼Œ**æ¸›å°‘æ¨¡å‹è¤‡é›œåº¦**ï¼Œé˜²æ­¢éæ“¬åˆã€‚                        |
| `max_depth=5`             | é™åˆ¶æ¯æ£µæ¨¹çš„æœ€å¤§æ·±åº¦ï¼Œé˜²æ­¢æ¨¡å‹å­¸ç¿’éå¤šç´°ç¯€ï¼ˆéæ“¬åˆï¼‰ã€‚                          |
| `n_estimators=1000`       | æœ€å¤šè¨“ç·´ 1000 æ£µæ¨¹ï¼Œå»ºè­°æ­é… `early_stopping_rounds` ä½¿ç”¨ä¾†é¿å…æµªè²»è³‡æºã€‚ |
| `reg_alpha=0.1`           | **L1 æ­£å‰‡åŒ–**ï¼ˆè®“éƒ¨åˆ†ç‰¹å¾µæ¬Šé‡è®Šæˆ 0ï¼Œé”åˆ°ç‰¹å¾µé¸æ“‡çš„æ•ˆæœï¼‰ï¼Œé˜²æ­¢éæ“¬åˆã€‚             |
| `reg_lambda=0.1`          | **L2 æ­£å‰‡åŒ–**ï¼ˆè®“æ¨¡å‹æ¬Šé‡ä¿æŒå¹³æ»‘ï¼‰ï¼ŒåŒæ¨£ç”¨æ–¼é˜²æ­¢éæ“¬åˆã€‚                     |
| `class_weight='balanced'` | è‡ªå‹•æ ¹æ“šè³‡æ–™ä¸­æ­£è² é¡åˆ¥çš„æ¯”ä¾‹èª¿æ•´æ¬Šé‡ï¼Œè§£æ±ºè³‡æ–™ä¸å¹³è¡¡å•é¡Œï¼ˆä¾‹å¦‚å›è³¼å®¢æˆ¶è¼ƒå°‘ï¼‰ã€‚              |
| `random_state=42`         | å›ºå®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—çµæœå¯é‡ç¾ã€‚                                    |


æ¨¡å‹è¨“ç·´ + Early Stopping


```python
from lightgbm import early_stopping, log_evaluation

callbacks = [early_stopping(stopping_rounds=50), log_evaluation(period=100)]

model.fit(
    X_train, y_train,
    categorical_feature=['customer_state_encoded'],  # å‘Šè¨´æ¨¡å‹é€™æ˜¯é¡åˆ¥ç‰¹å¾µ
    eval_set=[(X_test, y_test)], # è¨­å®šé©—è­‰é›†ï¼Œearly stopping å’Œè©•ä¼°æŒ‡æ¨™éƒ½æœƒæ ¹æ“šé€™çµ„è³‡æ–™ä¾†åˆ¤æ–·
    eval_metric='auc', # è©•ä¼°æŒ‡æ¨™é¸ç”¨ AUC
    callbacks = callbacks # åŠ å…¥å‰›å‰›å®šç¾©çš„å›èª¿å‡½æ•¸
)
```

    [LightGBM] [Info] Number of positive: 5085, number of negative: 74467
    [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005333 seconds.
    You can set `force_row_wise=true` to remove the overhead.
    And if memory is not enough, you can set `force_col_wise=true`.
    [LightGBM] [Info] Total Bins 296
    [LightGBM] [Info] Number of data points in the train set: 79552, number of used features: 9
    [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
    [LightGBM] [Info] Start training from score 0.000000
    Training until validation scores don't improve for 50 rounds
    [100]	valid_0's auc: 0.616087	valid_0's binary_logloss: 0.619044
    Early stopping, best iteration is:
    [60]	valid_0's auc: 0.621614	valid_0's binary_logloss: 0.628998
    

```python
# early_stoppingï¼šç•¶æ¨¡å‹åœ¨é©—è­‰é›†ä¸Šçš„è¡¨ç¾åœæ»¯ä¸€æ®µæ™‚é–“ï¼Œè‡ªå‹•åœæ­¢è¨“ç·´ã€‚
# log_evaluationï¼šå®šæœŸè¼¸å‡ºæ¨¡å‹è¨“ç·´çš„è©•ä¼°æŒ‡æ¨™ï¼Œæ–¹ä¾¿è§€å¯Ÿè¨“ç·´éç¨‹ã€‚
# early_stopping(stopping_rounds=50)ï¼šå¦‚æœæ¨¡å‹é€£çºŒ 50 æ¬¡è¿­ä»£æ²’æœ‰æå‡ï¼Œå°±åœæ­¢è¨“ç·´ï¼ˆé¿å…æµªè²»è¨ˆç®—è³‡æºï¼‰ã€‚
# log_evaluation(period=100)ï¼šæ¯ 100 æ¬¡è¿­ä»£è¼¸å‡ºä¸€æ¬¡è©•ä¼°æŒ‡æ¨™ï¼ˆä¾‹å¦‚ AUC åˆ†æ•¸ï¼‰ã€‚
```

æª¢æŸ¥ object å‹æ…‹ > LightGBM åªèƒ½è™•ç†æ•¸å€¼å‹æ…‹çš„è³‡æ–™


```python
print(features.dtypes[features.dtypes == 'object'])
```

    customer_unique_id    object
    order_id              object
    dtype: object
    

æª¢æŸ¥æ˜¯å¦ç™¼ç”Ÿè³‡æ–™æ´©æ¼

- ç‰¹å¾µé‡è¦æ€§ (Mutual Information Score) 


```python
from sklearn.feature_selection import mutual_info_classif

mi_scores = mutual_info_classif(X, y)
mi_df = pd.DataFrame({'Feature': X.columns, 'MI_Score': mi_scores})
print(mi_df.sort_values('MI_Score', ascending=False))
```

                        Feature  MI_Score
    0              monetary_avg  0.064858
    2               credit_card  0.018870
    7  main_payment_credit_card  0.018109
    6    customer_state_encoded  0.004350
    5                   voucher  0.002624
    1                    boleto  0.001704
    8   main_payment_debit_card  0.001623
    9      main_payment_voucher  0.000857
    4               not_defined  0.000097
    3                debit_card  0.000000
    

- ç›®æ¨™è®Šæ•¸åˆ†å¸ƒæ˜¯å¦åˆç†


```python
print(y.value_counts(normalize=True))
```

    is_repurchase
    0    0.936223
    1    0.063777
    Name: proportion, dtype: float64
    

- ä¿¡ç”¨å¡ä½¿ç”¨æ¬¡æ•¸é€éœ²æ˜¯å¦å›è³¼ > æ”¹æˆ "æ˜¯å¦ç”¨é" é€™å€‹ç‰¹å¾µ


```python
print(features.groupby('is_repurchase')['credit_card'].mean())
```

    is_repurchase
    0    0.769428
    1    0.821507
    Name: credit_card, dtype: float64
    

é æ¸¬çµæœ


```python
y_pred_prob = model.predict_proba(X_test)[:, 1]
y_pred = (y_pred_prob >= 0.7).astype(int)

print(f"AUC-ROC: {roc_auc_score(y_test, y_pred_prob):.4f}")
print(f"F1 Score: {f1_score(y_test, y_pred):.4f}")
print(f"Precision: {precision_score(y_test, y_pred):.4f}")
print(f"Recall: {recall_score(y_test, y_pred):.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))
```

    AUC-ROC: 0.6216
    F1 Score: 0.1956
    Precision: 0.4309
    Recall: 0.1265
    
    Classification Report:
                   precision    recall  f1-score   support
    
               0       0.94      0.99      0.97     18632
               1       0.43      0.13      0.20      1257
    
        accuracy                           0.93     19889
       macro avg       0.69      0.56      0.58     19889
    weighted avg       0.91      0.93      0.92     19889
    
    

| æŒ‡æ¨™            | æ•¸å€¼                  | è§£é‡‹                                                           |
| ------------- | ------------------- | ------------------------------------------------------------ |
| **AUC-ROC**   | 0.6216              | æ¨¡å‹å€åˆ†æ­£è² æ¨£æœ¬çš„èƒ½åŠ›ç•¥å„ªæ–¼éš¨æ©ŸçŒœæ¸¬ï¼ˆ0.5ï¼‰ï¼Œæ¨¡å‹èƒ½ä¸€å®šç¨‹åº¦å€åˆ†æœƒå›è³¼èˆ‡ä¸æœƒå›è³¼çš„å®¢æˆ¶ï¼Œä½†å€åˆ†èƒ½åŠ›åå¼±ã€‚        |
| **F1 Score**  | 0.1956              | Precision å’Œ Recall çš„ç¶œåˆè¡¨ç¾åä½ã€‚ç”±æ–¼ Precision é«˜ã€Recall ä½ï¼Œå°è‡´ F1 ä¸é«˜ã€‚ |
| **Precision** | **0.4309 (43.09%)** | é æ¸¬ã€Œæœƒå›è³¼ã€çš„å®¢æˆ¶ä¸­ï¼Œæœ‰ 43% çœŸå¯¦æœƒå›è³¼ï¼Œé€™æ˜¯è¡ŒéŠ·ä¸Šéå¸¸å¥½çš„ç²¾æº–ç‡ï¼Œé©åˆé«˜åƒ¹å€¼ç²¾æº–è¡ŒéŠ·ã€‚              |
| **Recall**    | 0.1265              | æ¨¡å‹åªæ‰¾å‡ºå¯¦éš›æœƒå›è³¼å®¢æˆ¶çš„ 12.65%ï¼Œè¡¨ç¤ºå¤§éƒ¨åˆ†æ½›åœ¨å›è³¼å®¢æˆ¶æ²’æœ‰è¢«é æ¸¬å‡ºä¾†ã€‚å±¬æ–¼ã€Œé«˜ç²¾æº–ã€ä½å¬å›ã€çš„ç­–ç•¥çµæœã€‚    |

| é¡åˆ¥      | precision | recall | f1-score | support | è§£é‡‹                                     |
| ------- | --------- | ------ | -------- | ------- | -------------------------------------- |
| 0 (æœªå›è³¼) | 0.94      | 0.99   | 0.97     | 18632   | é æ¸¬ã€Œä¸æœƒå›è³¼ã€éå¸¸æº–ç¢ºï¼Œæ¥µå°‘èª¤åˆ¤æˆæœƒå›è³¼ã€‚                 |
| 1 (å·²å›è³¼) | **0.43**  | 0.13   | 0.20     | 1257    | é æ¸¬ã€Œæœƒå›è³¼ã€æ™‚ï¼Œæœ‰ 43% çœŸçš„æœƒå›è³¼ï¼Œä½†åªæ‰¾åˆ°äº† 13% çš„å·²å›è³¼å®¢æˆ¶ã€‚ |


| æŒ‡æ¨™               | æ•¸å€¼                                           | è§£é‡‹                                           |
| ---------------- | -------------------------------------------- | -------------------------------------------- |
| **Accuracy**     | 0.93                                         | æº–ç¢ºç‡é«˜ï¼Œä½†é€™æ˜¯å› ç‚ºè³‡æ–™é«˜åº¦ä¸å¹³è¡¡ï¼Œå¤§éƒ¨åˆ†æ¨£æœ¬æœ¬ä¾†å°±æ˜¯æœªå›è³¼ã€‚              |
| **Macro Avg**    | 0.69 (Precision) / 0.56 (Recall) / 0.58 (F1) | å¹³å‡ä¾†çœ‹ï¼Œæ¨¡å‹åå‘æ­£ç¢ºé æ¸¬æœªå›è³¼å®¢æˆ¶ã€‚                          |
| **Weighted Avg** | 0.91 / 0.93 / 0.92                           | å› æœªå›è³¼æ¨£æœ¬å æ¯”éé«˜ï¼Œå°è‡´æ•´é«”æŒ‡æ¨™çœ‹èµ·ä¾†å¾ˆå¥½ï¼Œä½†é€™ä¸¦ä¸ä»£è¡¨æ¨¡å‹åœ¨ã€Œæœƒå›è³¼ã€é¡åˆ¥è¡¨ç¾è‰¯å¥½ã€‚ |

SHAP

```python
# !pip install shap
```

```python
import shap
import matplotlib.pyplot as plt
import lightgbm as lgb

# ç¢ºä¿ç”¨çš„æ˜¯åŸå§‹ç‰¹å¾µè³‡æ–™
# å‡è¨­ model å’Œ X éƒ½å·²ç¶“å®šç¾©ä¸¦ fit å®Œ

# å»ºç«‹ explainer
explainer = shap.Explainer(model)  # æ³¨æ„é€™è£¡ä¸æ˜¯ TreeExplainer è€Œæ˜¯è‡ªå‹•é¸æ“‡æœ€ä½³æ–¹å¼
shap_values = explainer(X)

# Summary Plotï¼ˆé‡å°é æ¸¬å€¼ç‚ºã€Œ1ã€çš„è§£é‡‹ï¼Œæœƒè‡ªå‹•åˆ¤æ–·ï¼‰
shap.summary_plot(shap_values.values, shap_values.data, feature_names=X.columns)
```

![png](practice_files/practice_77_0.png)


ç‰¹å¾µé‡è¦æ€§åˆ†æ


```python
import matplotlib.pyplot as plt

importances = model.feature_importances_
feature_names = X.columns

plt.figure(figsize=(8, 6))
plt.barh(feature_names, importances)
plt.title('Feature Importance')
plt.xlabel('Importance')
plt.tight_layout()
plt.show()
```


    
![png](practice_files/practice_89_0.png)
    


| ç‰¹å¾µåç¨±                         | é‡è¦æ€§æ’åº  | è§£é‡‹                             | è¡Œå‹•å»ºè­°                          |
| ---------------------------- | ------ | ------------------------------ | ----------------------------- |
| **monetary\_avg**            | æœ€é«˜ | å®¢æˆ¶å¹³å‡æ¶ˆè²»é‡‘é¡å°é æ¸¬å›è³¼å½±éŸ¿æœ€å¤§ï¼Œé‡‘é¡è¶Šé«˜ï¼Œå›è³¼æ©Ÿç‡è¶Šå¤§ã€‚ | å„ªå…ˆé‡å°é«˜æ¶ˆè²»å®¢æˆ¶è¡ŒéŠ·ï¼Œæä¾›å°ˆå±¬å„ªæƒ ï¼Œæé«˜å®¢å–®åƒ¹èˆ‡å›è³¼ç‡ã€‚ |
| **customer\_state\_encoded** | é«˜  | åœ°å€ï¼ˆå·ï¼‰å› ç´ å°å›è³¼æœ‰ä¸€å®šå½±éŸ¿ï¼Œä½†ä¸æ‡‰éåº¦ä¾è³´ã€‚       | é€²ä¸€æ­¥åˆ†æé«˜æ½›åŠ›å·åˆ¥ï¼Œåˆ¶å®šå€åŸŸè¡ŒéŠ·ç­–ç•¥ã€‚          |
| boleto                       | ä¸­é«˜ | ä½¿ç”¨ boleto ä»˜æ¬¾çš„å®¢æˆ¶å›è³¼å‚¾å‘è¼ƒé«˜ã€‚         | æä¾› boleto ä»˜æ¬¾å®¢æˆ¶ç›¸é—œä¿ƒéŠ·èˆ‡ä»˜æ¬¾å„ªæƒ æ–¹æ¡ˆã€‚    |
| credit\_card                 | ä¸­  | ä¿¡ç”¨å¡ä»˜æ¬¾å®¢æˆ¶æœ‰ä¸€å®šå›è³¼æ½›åŠ›ã€‚                | æ¨å‡ºä¿¡ç”¨å¡åˆ†æœŸã€å›é¥‹æ´»å‹•å¸å¼•å›è³¼ã€‚             |
| voucher                      | ä¸­  | ä½¿ç”¨å„ªæƒ åˆ¸ä»˜æ¬¾çš„å®¢æˆ¶æœ‰éƒ¨åˆ†å›è³¼æ½›åŠ›ã€‚             | é‡å°é€™é¡å®¢æˆ¶ç™¼é€å°ˆå±¬æŠ˜æ‰£åˆ¸æˆ–é™æ™‚å„ªæƒ ï¼Œåˆºæ¿€å›è³¼ã€‚      |
| not\_defined                 | ä½      | è³‡æ–™ä¸­ä»˜æ¬¾æ–¹å¼ç¼ºå¤±ï¼Œæ¨¡å‹å¹¾ä¹æœªä½¿ç”¨æ­¤è®Šæ•¸ã€‚          | å¯å¿½ç•¥ï¼Œç„¡éœ€ç‰¹åˆ¥è™•ç†æˆ–è¡ŒéŠ·æŠ•å…¥ã€‚              |
| debit\_card                  | ä½      | é‡‘èå¡ä»˜æ¬¾å®¢æˆ¶å°å›è³¼å½±éŸ¿åŠ›è¼ƒä½ã€‚               | ä¸€èˆ¬è¡ŒéŠ·å³å¯ï¼Œä¸éœ€ç‰¹åˆ¥è¨­è¨ˆé‡‘èå¡ä¿ƒéŠ·æ´»å‹•ã€‚         |
| main\_payment\_debit\_card   | å¹¾ä¹ç„¡è²¢ç»  | ä¸»è¦ä»˜æ¬¾æ–¹å¼ç‚ºé‡‘èå¡å°é æ¸¬å½±éŸ¿æ¥µä½ã€‚             | å¯ä»¥è€ƒæ…®åˆªé™¤è©²è®Šæ•¸ï¼Œä¸å½±éŸ¿æ¨¡å‹æ•ˆæœã€‚            |
| main\_payment\_credit\_card  | å¹¾ä¹ç„¡è²¢ç»  | ä¸»è¦ä»˜æ¬¾æ–¹å¼ç‚ºä¿¡ç”¨å¡çš„å€åˆ†æ„ç¾©ä¸å¤§ã€‚             | å¯ç§»é™¤ã€‚                          |
| main\_payment\_voucher       | å¹¾ä¹ç„¡è²¢ç»  | ä¸»è¦ä½¿ç”¨å„ªæƒ åˆ¸ä»˜æ¬¾çš„å½±éŸ¿æ¥µä½ã€‚                | å¯ç§»é™¤ã€‚                          |


é«˜å›è³¼æ½›åŠ›å®¢æˆ¶åå–®


```python
features['repurchase_prob'] = model.predict_proba(X)[:, 1]
high_potential_customers = features[features['repurchase_prob'] >= 0.7][
    ['customer_unique_id', 'repurchase_prob']
].sort_values(by='repurchase_prob', ascending=False)

print("ğŸ“Œ Top 10 High Repurchase Probability Customers:")
print(high_potential_customers.head(10))

# å¯ä»¥ç›´æ¥å­˜æª”
# high_potential_customers.to_csv('high_potential_customers.csv', index=False)
high_potential_customers.head()
```

    ğŸ“Œ Top 10 High Repurchase Probability Customers:
                         customer_unique_id  repurchase_prob
    22372  397b44d5bb99eabf54ea9c2b41ebb905         0.973697
    22373  397b44d5bb99eabf54ea9c2b41ebb905         0.973697
    22370  397b44d5bb99eabf54ea9c2b41ebb905         0.973697
    22371  397b44d5bb99eabf54ea9c2b41ebb905         0.973697
    66353  aa89a987e1e092c318fbdc4b0e3dcc44         0.971189
    66352  aa89a987e1e092c318fbdc4b0e3dcc44         0.971189
    9749   18e3d276253780b44b5b7bf83f6785ec         0.971189
    9750   18e3d276253780b44b5b7bf83f6785ec         0.971189
    9751   18e3d276253780b44b5b7bf83f6785ec         0.971189
    91263  eaa604ab9f816252edb7a8d297f932e5         0.970622
    




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_unique_id</th>
      <th>repurchase_prob</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>22372</th>
      <td>397b44d5bb99eabf54ea9c2b41ebb905</td>
      <td>0.973697</td>
    </tr>
    <tr>
      <th>22373</th>
      <td>397b44d5bb99eabf54ea9c2b41ebb905</td>
      <td>0.973697</td>
    </tr>
    <tr>
      <th>22370</th>
      <td>397b44d5bb99eabf54ea9c2b41ebb905</td>
      <td>0.973697</td>
    </tr>
    <tr>
      <th>22371</th>
      <td>397b44d5bb99eabf54ea9c2b41ebb905</td>
      <td>0.973697</td>
    </tr>
    <tr>
      <th>66353</th>
      <td>aa89a987e1e092c318fbdc4b0e3dcc44</td>
      <td>0.971189</td>
    </tr>
  </tbody>
</table>
</div>

[ğŸ”¼è¿”å›ç›®éŒ„](#ç›®éŒ„)

### **5. å®¢æˆ¶åˆ†ç¾¤åˆ†æ (Audience Segmentation)** 

æº–å‚™åˆ†ç¾¤ç‰¹å¾µ

- RFM æ¨¡å‹èˆ‡å›è³¼æ©Ÿç‡

| ç‰¹å¾µ        | èªªæ˜         |
| --------- | ---------- |
| Recency   | æœ€è¿‘ä¸€æ¬¡è³¼è²·è·é›¢å¹¾å¤© |
| Frequency | è³¼è²·æ¬¡æ•¸       |
| Monetary  | å¹³å‡æ¶ˆè²»é‡‘é¡     |
| Repurchase prob.  | å†æ¬¡è³¼è²·çš„æ©Ÿç‡     |



```python
high_potential_customers = pd.merge(
    high_potential_customers,  # å·¦è¡¨ï¼šåªåŒ…å«é«˜æ½›åŠ›å®¢æˆ¶çš„ ID å’Œé æ¸¬æ©Ÿç‡
    features[['customer_unique_id', 'recency_days', 'order_count', 'monetary_avg']],  # å³è¡¨ï¼šå®Œæ•´ç‰¹å¾µ
    on='customer_unique_id',
    how='left'
)

segmentation_features = high_potential_customers[['recency_days', 'order_count', 'monetary_avg', 'repurchase_prob']]

# ç¢ºä¿æ²’æœ‰ç¼ºå¤±å€¼
segmentation_features.fillna(0, inplace=True)
```

ç‰¹å¾µæ¨™æº–åŒ–ï¼ˆStandardizationï¼‰> å› ç‚º K-Means å°æ•¸å€¼ç¯„åœå¾ˆæ•æ„Ÿ


```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
segmentation_scaled = scaler.fit_transform(segmentation_features)
```

ä½¿ç”¨ K-Means åˆ†ç¾¤

- æ±ºå®šæœ€ä½³ç¾¤æ•¸ï¼ˆElbow Methodï¼‰


```python
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

sse = []
for k in range(1, 10):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(segmentation_scaled)
    sse.append(kmeans.inertia_)

plt.plot(range(1, 10), sse, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('SSE (Inertia)')
plt.title('Elbow Method for Optimal k')
plt.show()
```


    
![png](practice_files/practice_100_0.png)
    


- æ­£å¼åˆ†ç¾¤ (å…ˆå˜—è©¦ k = 2)


```python
kmeans = KMeans(n_clusters=2, random_state=42)
high_potential_customers['customer_segment'] = kmeans.fit_predict(segmentation_scaled)
```

åˆ†æåˆ†ç¾¤çµæœ


```python
segment_analysis = high_potential_customers.groupby('customer_segment')[['recency_days', 'order_count', 'monetary_avg', 'repurchase_prob']].mean()
print(segment_analysis)
```

                      recency_days  order_count  monetary_avg  repurchase_prob
    customer_segment                                                          
    0                   214.250379     2.893778    149.597473         0.907889
    1                   272.500000     1.529675    175.049118         0.734802
    

- å®¢ç¾¤è¦æ¨¡å æ¯”


```python
group_distribution = high_potential_customers['customer_segment'].value_counts(normalize=True) * 100
print(group_distribution)
```

    customer_segment
    1    57.53866
    0    42.46134
    Name: proportion, dtype: float64
    

åˆä½µè¡¨æ ¼


```python
# å°‡ group_distribution è½‰æˆ DataFrame ä¸¦é‡è¨­æ¬„ä½åç¨±
group_distribution_df = group_distribution.rename('percentage (%)').reset_index()
group_distribution_df.columns = ['customer_segment', 'percentage (%)']

# segment_analysis åŸæœ¬çš„ index æ˜¯ customer_segmentï¼Œå…ˆé‡è¨­ index
segment_analysis = segment_analysis.reset_index()

# åˆä½µå…©å€‹ DataFrame
merged_df = pd.merge(segment_analysis, group_distribution_df, on='customer_segment')

# æŒ‰ç¾¤çµ„æ’åºï¼ˆå¦‚æœéœ€è¦ï¼‰
merged_df = merged_df.sort_values('customer_segment').reset_index(drop=True)

# é¡¯ç¤ºçµæœ
print(merged_df.to_string(index=False))
```

     customer_segment  recency_days  order_count  monetary_avg  repurchase_prob  percentage (%)
                    0    214.250379     2.893778    149.597473         0.907889        42.46134
                    1    272.500000     1.529675    175.049118         0.734802        57.53866
    

å»¶ä¼¸ k = 5


```python
kmeans = KMeans(n_clusters=5, random_state=42)
high_potential_customers['customer_segment'] = kmeans.fit_predict(segmentation_scaled)

segment_analysis = high_potential_customers.groupby('customer_segment')[['recency_days', 'order_count', 'monetary_avg', 'repurchase_prob']].mean()

group_distribution = high_potential_customers['customer_segment'].value_counts(normalize=True) * 100

group_distribution_df = group_distribution.rename('percentage (%)').reset_index()
group_distribution_df.columns = ['customer_segment', 'percentage (%)']

segment_analysis = segment_analysis.reset_index()

merged_df = pd.merge(segment_analysis, group_distribution_df, on='customer_segment')

merged_df = merged_df.sort_values('customer_segment').reset_index(drop=True)

print(merged_df.to_string(index=False))
```

     customer_segment  recency_days  order_count  monetary_avg  repurchase_prob  percentage (%)
                    0    163.423540     1.650602    156.981812         0.735429       34.761598
                    1    445.726098     1.395349    148.980504         0.749997       24.935567
                    2    172.522727     5.575758    184.813144         0.919258        8.505155
                    3     86.692308     2.384615   2806.627692         0.718071        0.418814
                    4    206.435318     2.240246    143.568871         0.906478       31.378866
    

è¡ŒéŠ·ç­–ç•¥

k = 2

| **ç¾¤çµ„**    | **Recencyï¼ˆå¤©ï¼‰** | **Frequency** | **Monetary** | **å›è³¼æ©Ÿç‡ (%)** | **å®¢æˆ¶ç‰¹å¾µ**         | **å æ¯” (%)** | **é æœŸè¡ŒéŠ·è²¢ç»** | **è¡ŒéŠ·å„ªå…ˆç´š** | **è¡ŒéŠ·ç­–ç•¥å»ºè­°**                                 |
| --------- | -------------- | ------------- | ------------ | ------------ | ---------------- | ---------- | ---------- | --------- | ------------------------------------------ |
| 0 | 214            | 2.89          | 149.60       | 90.79        | é«˜å›è³¼ç‡ã€å·²å¤šæ¬¡è³¼è²·ã€æ¶ˆè²»ä¸­ç­‰  | 42.46      | æé«˜å®¢å–®åƒ¹ï¼Œæå‡ç²åˆ© | **é«˜**     | - æ¨è–¦é«˜åƒ¹å€¼å•†å“çµ„åˆ<br>- è¨­è¨ˆæœƒå“¡å°ˆå±¬ç¦åˆ©èˆ‡ç©åˆ†è¨ˆç•«<br>- æ»¿é¡æŠ˜æ‰£/å‡ç´šå„ªæƒ     |
| 1 | 272            | 1.53          | 175.05       | 73.48        | ä½å›è³¼ç‡ã€æ¶ˆè²»é‡‘é¡è¼ƒé«˜ã€æµå¤±é¢¨éšª | 57.54      | åˆºæ¿€å›è³¼ï¼Œæé«˜å›è³¼ç‡ | **ä¸­**     | - æä¾›é™æ™‚æŠ˜æ‰£<br>- ç²¾æº–æ¨æ’­ EDM/LINE æé†’<br>- é¦–æ¬¡å›è³¼å„ªæƒ æ´»å‹• |

k = 5 (æœ€çµ‚é¸æ“‡)

| **ç¾¤çµ„**    | **Recencyï¼ˆå¤©ï¼‰** | **Frequency** | **Monetary** | **å›è³¼æ©Ÿç‡ (%)** | **å®¢æˆ¶ç‰¹å¾µ**         | **å æ¯” (%)** | **é æœŸè¡ŒéŠ·è²¢ç»** | **è¡ŒéŠ·å„ªå…ˆç´š** | **è¡ŒéŠ·ç­–ç•¥å»ºè­°**                            |
| --------- | -------------- | ------------- | ------------ | ------------ | ---------------- | ---------- | ---------- | --------- | ------------------------------------- |
| 0 | 163.42         | 1.65          | 156.98       | 73.54        | æ–°å®¢å‰›å»ºç«‹é—œä¿‚ã€å›è³¼æ©Ÿæœƒé©ä¸­   | 34.76      | åˆºæ¿€å›è³¼ï¼Œæé«˜è½‰æ›ç‡ | **é«˜**     | - æä¾›é¦–æ¬¡å›è³¼å„ªæƒ <br>- é™æ™‚æŠ˜æ‰£æ¨æ’­<br>- å¼•å°åŠ å…¥æœƒå“¡ç‰¹åˆ¥æ´»å‹•        |
| 1 | 445.73         | 1.40          | 148.98       | 75.00        | é•·æ™‚é–“æœªå›è³¼ã€å³å°‡æµå¤±      | 24.94      | æŒ½å›æµå¤±ï¼Œæé«˜å›è³¼ç‡ | **ä¸­**     | - æä¾›é«˜èª˜å› æŠ˜æ‰£åˆ¸<br>- æ¨å‡ºå›æµå°ˆå±¬å„ªæƒ <br>- EDM/LINE å–šå›è¡ŒéŠ· |
| 2 | 172.52         | 5.58          | 184.81       | 91.93        | ç©©å®šå›è³¼ã€é«˜å›è³¼æ©Ÿç‡ã€æ¶ˆè²»åé«˜  | 8.51       | ç©©å®šé«˜åˆ©æ½¤è²¢ç»    | **æœ€é«˜**    | - æä¾› VIP å°ˆå±¬å„ªæƒ <br>- æ¨è–¦è¼ƒé«˜åƒ¹å•†å“çµ„åˆ<br>- å»ºç«‹é•·æœŸæœƒå“¡è¨ˆç•«   |
| 3 | 86.69          | 2.38          | 2806.63      | 71.81        | è¶…é«˜æ¶ˆè²»ä½†å›è³¼ç‡åä½       | 0.42       | é«˜å–®åƒ¹æ½›åŠ›å®¢æˆ¶    | **ä¸­**     | - ç²¾æº–æ¨è–¦é«˜åƒ¹ç”¢å“<br>- é«˜åƒ¹å€¼å®¢æˆ¶å°ˆå±¬æœå‹™<br>- é—œä¿‚ç®¡ç†åŠ å¼·       |
| 4 | 206.44         | 2.24          | 143.57       | 90.65        | å›è³¼é »ç‡é«˜ã€å›è³¼æ©Ÿç‡é«˜ã€æ¶ˆè²»é©ä¸­ | 31.38      | ç©©å®šæ”¶å…¥è²¢ç»     | **é«˜**     | - æ¨è–¦å®šæœŸè³¼è²·æ–¹æ¡ˆ<br>- æœƒå“¡ç©åˆ†å…Œæ›ä¿ƒéŠ·<br>- æå‡å–®æ¬¡æ¶ˆè²»é¡        |

[ğŸ”¼è¿”å›ç›®éŒ„](#ç›®éŒ„)

### **6. çµè«–èˆ‡å»ºè­°**

- **çµè«–**

  é€éä»¥ä¸Šåˆ†æäº†è§£å½±éŸ¿å›è³¼è¡Œç‚ºçš„é—œéµå› ç´ èˆ‡é¡§å®¢ç‰¹æ€§ï¼Œä¸»è¦ç™¼ç¾å¦‚ä¸‹ï¼š

1. **æ•´é«”å›è³¼ç‡åä½**

   æ ¹æ“šæ¼æ–—åˆ†æçµæœï¼Œ96096 ä½ç¸½è³¼è²·è€…ä¸­åƒ…æœ‰ 2997 äººå†æ¬¡ä¸‹å–®ï¼Œå›è³¼ç‡ç´„ 3.12%ï¼Œé¡¯ç¤ºç¾æœ‰è¡ŒéŠ·ç­–ç•¥åœ¨ä¿ƒä½¿å›è³¼æ–¹é¢æœ‰æ”¹å–„ç©ºé–“ã€‚

2. **æ¨¡å‹é æ¸¬æ•ˆèƒ½ä¸­ç­‰ï¼Œä»å…·åƒè€ƒåƒ¹å€¼**

   LightGBM æ¨¡å‹çš„ AUC-ROC ç‚º 0.6216ï¼Œé¡¯ç¤ºæ¨¡å‹å°ã€Œæ˜¯å¦å›è³¼ã€å…·æœ‰ä¸€å®šå€åˆ†èƒ½åŠ›ã€‚Precision é” 43.1%ï¼Œä»£è¡¨æ¨¡å‹æ¨è–¦çš„æ½›åœ¨å›è³¼å®¢æˆ¶ä¸­ï¼Œæœ‰ç›¸ç•¶æ¯”ä¾‹ç¢ºå¯¦æœƒå›è³¼ï¼Œå¯æœ‰æ•ˆå”åŠ©ç²¾æº–è¡ŒéŠ·èˆ‡è³‡æºé›†ä¸­æŠ•æ”¾ã€‚Recall ç‚º 12.65%ï¼Œä»£è¡¨æ•´é«”æ½›åœ¨å›è³¼è€…ä¸­ï¼Œæ¨¡å‹èƒ½æ•æ‰çš„æ¯”ä¾‹åä½ï¼Œåå‘ä¿å®ˆé æ¸¬ç­–ç•¥ï¼Œå¯é¿å…èª¤åˆ¤ä½†ä¹Ÿå£“ç¸®è§¸åŠç¯„åœã€‚é›–ç„¶ F1-score ç‚º 0.1956ï¼Œä¸»è¦å—é™æ–¼è³‡æ–™ä¸å¹³è¡¡ï¼Œä½†æ•´é«”æ¨¡å‹å¯å”åŠ©åˆæ­¥ç¯©é¸å‡ºæ½›åœ¨å›è³¼å®¢æˆ¶ã€‚

3. **å½±éŸ¿å›è³¼çš„é—œéµè®Šæ•¸**

   ç”±ç‰¹å¾µé‡è¦æ€§èˆ‡ SHAP åˆ†æå¯çŸ¥ï¼Œå½±éŸ¿å›è³¼æœ€é¡¯è‘—çš„è®Šæ•¸åŒ…æ‹¬ï¼š
   - å¹³å‡æ¶ˆè²»é‡‘é¡ï¼ˆmonetary_avgï¼‰ï¼šæ¶ˆè²»è¶Šé«˜è€…å‚¾å‘å†æ¬¡è³¼è²·ã€‚
   - ä»˜æ¬¾æ–¹å¼ï¼šä½¿ç”¨ç‰¹å®šä»˜æ¬¾æ–¹å¼ï¼ˆå¦‚ä¿¡ç”¨å¡ã€boletoï¼‰å°æ¨¡å‹è¼¸å‡ºæœ‰æ­£å‘å½±éŸ¿ã€‚
   - é¡§å®¢æ‰€åœ¨å·ï¼ˆcustomer_state_encodedï¼‰ï¼šé¡¯ç¤ºåœ°å€æ€§æ¶ˆè²»è¡Œç‚ºå·®ç•°ã€‚

4. **æ½›åœ¨åƒ¹å€¼å®¢ç¾¤**
   - ç¬¬ 2 ç¾¤ï¼ˆç©©å®šå›è³¼ã€æ¶ˆè²»åé«˜ï¼‰èˆ‡ç¬¬ 4 ç¾¤ï¼ˆå›è³¼é »ç‡é«˜ã€æ¶ˆè²»é©ä¸­ï¼‰å…·æœ‰æœ€é«˜å›è³¼æ©Ÿç‡ï¼ˆçš†é€¾ 0.9ï¼‰ï¼Œç‚ºå¯å„ªå…ˆé–å®šçš„é«˜æ½›åŠ›å°è±¡ã€‚
   - ç¬¬ 3 ç¾¤ï¼ˆè¶…é«˜æ¶ˆè²»åŠ›ï¼‰é›–ç„¶å›è³¼ç‡æ™®é€šï¼ˆ0.718ï¼‰ï¼Œä½†å…¶å¹³å‡æ¶ˆè²»é«˜é” 2806 å…ƒï¼Œç‚ºã€Œé«˜åƒ¹å€¼ä½é »ç‡ã€æ—ç¾¤ï¼Œå¯é€éç‰¹æ®Šå•†å“æ¨è–¦ç¶­ç¹«é—œä¿‚ã€‚
   - ç¬¬ 1 ç¾¤ï¼ˆé•·æ™‚é–“æœªå›è³¼ï¼‰å‰‡ç‚ºã€Œä½åƒ¹å€¼ä½æ´»èºã€æ—ç¾¤ï¼Œæ‡‰è¬¹æ…æŠ•å…¥è¡ŒéŠ·è³‡æºã€‚
     
- **ç­–ç•¥å»ºè­°**

1. **æå‡å›è³¼èª˜å› çš„å€‹äººåŒ–è¡ŒéŠ·ç­–ç•¥**
   - å°å›è³¼æ©Ÿç‡é«˜çš„ç¾¤é«”ï¼ˆå¦‚ç¬¬ 2 ç¾¤ã€ç¬¬ 2 ç¾¤ï¼‰å¯æ¨è¡Œé™æ™‚æŠ˜æ‰£ã€æœƒå“¡å°ˆå±¬æ´»å‹•ã€‚
   - å°æ¶ˆè²»é‡‘é¡é«˜ä½†å›è³¼æ©Ÿç‡ä¸­ç­‰çš„ç¾¤é«”ï¼ˆç¬¬ 3 ç¾¤ï¼‰ï¼Œå¼·åŒ–å®¢è£½åŒ–æ¨è–¦èˆ‡å°Šæ¦®å›é¥‹æ–¹æ¡ˆã€‚
   - å°æ–°å®¢æˆ¶ï¼ˆç¬¬ 0 ç¾¤ï¼‰è¨­è¨ˆé¦–æ¬¡å›è³¼èª˜å› æ´»å‹•ï¼ˆå¦‚æ»¿é¡æŠ˜æ‰£ï¼‰ï¼Œå¢åŠ çŸ­æœŸå›è³¼æ©Ÿç‡ã€‚

2. **ä»˜æ¬¾æ–¹å¼èˆ‡åœ°å€æ€§è¡ŒéŠ·æ‡‰ç”¨**
   - é‡å°å„ªæƒ åˆ¸èˆ‡ä¿¡ç”¨å¡å®¢ç¾¤æä¾›å°ˆå±¬å›é¥‹æ´»å‹•ï¼Œæå‡å¿ èª åº¦èˆ‡å›è³¼ç‡ã€‚
   - åœ°å€æ€§é¡§å®¢æ¶ˆè²»è¡¨ç¾ä¸åŒï¼Œ AC å’Œ RO å·çš„å›è³¼ç‡è¶…é 9%ï¼Œå¯æŠ•å…¥æ›´å¤šè¡ŒéŠ·è³‡æºèˆ‡ä¿ƒéŠ·æ´»å‹•ï¼›è€Œ CE å’Œ AP å·çš„å›è³¼ç‡è¼ƒä½ï¼Œå¯é©åº¦é™ä½è¡ŒéŠ·è³‡æºé…ç½®æˆ–èª¿æ•´ç”¢å“ç­–ç•¥ã€‚ 

3. **å¾ŒçºŒæ‡‰ç”¨èˆ‡æ¨¡å‹ç²¾é€²æ–¹å‘**
   - å®Œå–„ä¸å¹³è¡¡å•é¡Œä»¥å¼·åŒ– Recall è¡¨ç¾ã€‚
   - åŠ å…¥å•†å“é¡åˆ¥ã€ç€è¦½åŠè³¼ç‰©è¡Œç‚ºç­‰è³‡æ–™åˆ°æ¨¡å‹ï¼Œé‡å°ä¸åŒé¡åˆ¥å®¢æˆ¶é€²è¡Œç´°åˆ†å»ºæ¨¡ï¼Œä»¥æå‡ Recall èˆ‡è¡ŒéŠ·æˆæ•ˆã€‚
 
[ğŸ”¼è¿”å›ç›®éŒ„](#ç›®éŒ„)
